{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising Weather prediction on Omniverse - FourCastNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will give you a start in obtaining inference results from FourCastNet and visualising the results on our Omniverse Digital Twin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents of the Notebook\n",
    "\n",
    "- [Building an extension to visualise weather prediction using FourCastNet](#Building-an-extension-to-visualise-weather-prediction-using-FourCastNet)\n",
    "    - [Obtaining results from FourCastNet](#Obtaining-results-from-FourCastNet)\n",
    "    - [Visualising results in Omniverse](#Visualising-results-in-Omniverse)\n",
    "    - [Mini challenge - Visualising the Total column water vapour channel](#Mini-challenge---Visualising-Total-Column-Water-Vapour)\n",
    "        \n",
    "#### Learning Outcomes\n",
    "- How to get started in Omniverse\n",
    "- Visualising our data using custom-built extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an extension to visualise weather prediction using FourCastNet\n",
    "\n",
    "Let us follow a step-by-step approach to building an extension on Omniverse and use the results obtained from FourCastNet to visualise a Digital Twin of Earth.\n",
    "\n",
    "These steps assume you have followed the previous notebook (Visualising Navier-Stoke weather prediction on Omniverse) to complete the first set of visualisation. Before we proceed forward to modify our plugin, let us first generate results from a Trained FourCastNet Model. The Trained FourCastNet model is available to us as an open-source repository on GitHub - [FourCastNet](https://github.com/NVlabs/FourCastNet)\n",
    "\n",
    "### Obtaining results from FourCastNet \n",
    "\n",
    "Let us now run the inference for the FourCastNet model to obtain the outputs, which we can further process and visualise in our system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional - Visualising real-time results - Downloading dataset \n",
    "\n",
    "A sample of data for one day is already downloaded and present in the container, but if the container has access to the Internet, you can download the latest data available to see predictions on the day you are running the material. \n",
    "\n",
    "- **Steps to download the latest data available to us** \n",
    "    - Create a new account on the [Copernicus Climate Change Service Data Store](https://cds.climate.copernicus.eu/user/register?destination=%2F%23!%2Fhome) and log in to your account\n",
    "    - Head over to [ERA5 Reanalysis hourly pressure data](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=form) page and set the year and month column to find out what is the latest data available, this dataset is updated with a latency of 5 days. Kindly make a note of the date available to us. For this example, we will use **March 27 2023**. \n",
    "    - Modify the files accordingly to use the latest date available and set the appropriate location to download and store the data [get_data_pl_short_length.py](../../source_code/FCN/copernicus/get_data_pl_short_length.py) & [get_data_sfc_short_length.py](../../source_code/FCN/copernicus/get_data_sfc_short_length.py)\n",
    "    - Obtain your API key from [here](https://cds.climate.copernicus.eu/api-how-to)\n",
    "    - Open a new Terminal and create a new file ( `touch $HOME/.cdsapirc` ) and add your API key ( `nano $HOME/.cdsapirc` ), and save and close. \n",
    "    - Download the data by running the cell below\n",
    "    - Verify if all the locations are correct in our data_preprocessing script present [here](../../source_code/FCN/data_process/parallel_copy_small_set.py) and run the script to make them compatible with the FourCastNet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional \n",
    "# Download PL and SFC for building our inference data \n",
    "!python3 ../../source_code/FCN/copernicus/get_data_pl_short_length.py && python3 ../../source_code/FCN/copernicus/get_data_sfc_short_length.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "# Pre-processing the downloaded data to make it compatible with FourCastNet \n",
    "!python3 ../../source_code/FCN/data_process/parallel_copy_small_set.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running inference on the dataset\n",
    "\n",
    "Let us now run an inference on the dataset using the FourCastNet Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd ../../source_code/FCN && python3 inference/inference.py --vis --config=afno_backbone --run_num=0 \\\n",
    "        --weights \"/workspace/python/source_code/FCN/FCN_weights_v0/backbone.ckpt\" \\\n",
    "        --override_dir \"/workspace/python/source_code/FCN/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have run our inference, we can see the first three days have minimal error, because they are the prediction for Day 0 at different time steps whereas, the remaining predictions are compared to a dummy value, Let us now convert these predictions to images and have them stored for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the outputs from h5py file to images and storing them in the assets folder\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "variable=['u10','v10','t2m','sp','msl','t_850','u_1000','v_1000','z_1000','u_850','v_850',\n",
    "            'z_850','u_500','v_500','z_500','t_500','z_50','r_500','r_850','tcwv']\n",
    "\n",
    "filename = \"../../source_code/FCN/output/autoregressive_predictions_z500_vis.h5\"\n",
    "hf = h5py.File(filename, 'r')\n",
    "data = hf.get('predicted')[0]\n",
    "\n",
    "##### Setting j=0 to visualise u10 (Eastward component of wind at sea level)\n",
    "j=0\n",
    "#####\n",
    "\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    # Get the graph \n",
    "    plt.imshow(data[i][j],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # Save as image\n",
    "    store_loc = \"/../../source_code/extension/assets/FCN_output/\"+variable[j]+'/'\n",
    "    if not os.path.exists(os.getcwd()+store_loc):\n",
    "        os.makedirs(os.getcwd()+store_loc)\n",
    "    plt.savefig(os.getcwd()+store_loc+str(i)+'.jpg',bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising results in Omniverse\n",
    "\n",
    "\n",
    "#### 1. Modify the extension \n",
    "\n",
    "We can either create a new extension or modify the existing extension for FourCastNet. In this case, we will be modifying the existing extension. If needed, you can go ahead to create a new extension. \n",
    "\n",
    "Open the [`extension.py`](../../source_code/extension/omniverse-project-navier-stokes2/exts/omniverse.extension.navierstokes/omniverse/extension/navierstokes/extension.py) file for modifications. \n",
    "\n",
    "Let us now change the directory and TimeCode to reflect the results of FourCastNet.\n",
    "\n",
    "\n",
    "```python\n",
    "import omni.ext\n",
    "import omni.ui as ui\n",
    "from pxr import Usd, UsdShade, Sdf\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# Any class derived from `omni.ext.IExt` in top level module (defined in `python.modules` of `extension.toml`) will be\n",
    "# instantiated when extension gets enabled and `on_startup(ext_id)` will be called. Later when extension gets disabled\n",
    "# on_shutdown() is called.\n",
    "class OmniverseExtensionNavierstokesExtension(omni.ext.IExt):\n",
    "    # ext_id is current extension id. It can be used with extension manager to query additional information, like where\n",
    "    # this extension is located on filesystem.\n",
    "    def on_startup(self, ext_id):\n",
    "        print(\"[omniverse.extension.navierstokes] omniverse extension navierstokes startup\")\n",
    "        \n",
    "        # Get shader input for opacity map\n",
    "        stage = omni.usd.get_context().get_stage()\n",
    "        shader = UsdShade.Shader.Get(stage,\"/World/Looks/Clouds/Shader\")\n",
    "        texture = shader.GetInput(\"opacity_texture\")\n",
    "\n",
    "        # Get and store image paths \n",
    "        files=[]\n",
    "        for i in range(30):\n",
    "            files.append(os.getcwd()+'/../extension/assets/FCN_output/u10/'+str(i)+'.jpg')\n",
    "        \n",
    "        # Assign images every 5 timesteps\n",
    "        texture.GetAttr().Clear()\n",
    "        for i in range(30):\n",
    "            texture.Set(Sdf.AssetPath(files[i]),Usd.TimeCode(5*i))\n",
    "                        \n",
    "        # Trim Timeline\n",
    "        stage.SetStartTimeCode(0)\n",
    "        stage.SetEndTimeCode(150)\n",
    "        \n",
    "        \n",
    "    def on_shutdown(self):\n",
    "        print(\"[omniverse.extension.navierstokes] omniverse extension navierstokes shutdown\")\n",
    "```\n",
    "\n",
    "#### 2. Setting \"Opacity Map Color Space\" to `auto`\n",
    "\n",
    "We can now set the `Opacity Map Color Space` to `auto` for the application to auto-detect the color space of our textures and apply them on top of the Digital Twin. \n",
    "\n",
    "<center><img src=\"images/ext10.png\" alt=\"Drawing\" style=\"width:1000px\" /></center>\n",
    "\n",
    "#### 3. Playing the animation\n",
    "\n",
    "You can play the animation by clicking on the `Play` button present on the left side of the taskbar. \n",
    "\n",
    "The first time we run it, it takes a bit of time to load all the textures, after which the animations fell smoother once loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"images/fcn.mp4\" controls loop autoplay  width=\"1200\"  height=\"600\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"images/fcn.mp4\",width=1200, height=600,html_attributes='controls loop autoplay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini challenge - Visualising Total Column Water Vapour\n",
    "\n",
    "Similar to the approach above, the Mini challenge is to visualize the Total column water vapour variable using Omniverse. You will be provided with snippets that you can fill in the TODO blanks to solve the challenge and visualize the results. Before moving to the challenge, let us have a brief of what Total column water vapour is and how useful it is to atmospheric science. \n",
    "\n",
    "#### Total column water vapour (TCWV)\n",
    "\n",
    "Total column water vapour (TCWV) refers to the amount of water vapour present in a vertical column of the atmosphere that extends from the Earth's surface to the top of the atmosphere. It is usually expressed in units of millimetres or centimetres of water vapour thickness over a unit area.\n",
    "\n",
    "TCWV is a critical parameter in atmospheric science, as it plays a crucial role in the Earth's energy balance and the water cycle. It affects the formation of clouds and precipitation, and it is an essential component of climate models. Some of the ways in which TCWV is useful to include:\n",
    "\n",
    "- **Climate research**: TCWV is a crucial component of climate models, which are used to understand and predict long-term changes in the Earth's climate. Accurate measurements of TCWV help to improve the accuracy of these models and provide insights into the role of water vapour in the Earth's climate system.\n",
    "\n",
    "- **Weather forecasting**: TCWV measurements can be used to predict short-term weather events, such as heavy rainfall, thunderstorms, and tropical cyclones. This information is particularly important for forecasting severe weather events, which can cause significant damage to property and human life.\n",
    "\n",
    "- **Agriculture**: TCWV measurements can be used to monitor soil moisture levels, which are critical for crop growth and yield. Accurate measurements of TCWV can help farmers to optimize irrigation schedules and reduce water usage, which can lead to increased crop productivity and profitability.\n",
    "\n",
    "- **Aviation**: TCWV measurements are used in aviation to improve safety and efficiency. Water vapour in the atmosphere can cause turbulence and affect the performance of aircraft engines. Accurate TCWV measurements can help pilots to avoid areas of turbulence and adjust their flight paths to minimize fuel consumption.\n",
    "\n",
    "Overall, TCWV is a crucial parameter for understanding the Earth's atmospheric system, and it provides essential information which is used for making informed decisions in a range of industries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Converting outputs for TCWV and storing them in the assets folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the outputs from h5py file to images and storing them in the assets folder\n",
    "import h5py\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "variable=['u10','v10','t2m','sp','msl','t_850','u_1000','v_1000','z_1000','u_850','v_850',\n",
    "            'z_850','u_500','v_500','z_500','t_500','z_50','r_500','r_850','tcwv']\n",
    "\n",
    "filename = \"../../source_code/FCN/output/autoregressive_predictions_z500_vis.h5\"\n",
    "hf = h5py.File(filename, 'r')\n",
    "data = hf.get('predicted')[0]\n",
    "\n",
    "####### TODO ########\n",
    "j=0 \n",
    "###################### \n",
    "    \n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    # Get the graph \n",
    "    plt.imshow(data[i][j],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # Save as image\n",
    "    store_loc = \"/../../source_code/extension/assets/FCN_output/\"+variable[j]+'/'\n",
    "    if not os.path.exists(os.getcwd()+store_loc):\n",
    "        os.makedirs(os.getcwd()+store_loc)\n",
    "    plt.savefig(os.getcwd()+store_loc+str(i)+'.jpg',bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "##################### Solution #####################\n",
    "# Converting the outputs from h5py file to images and storing them in the assets folder\n",
    "import h5py\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "variable=['u10','v10','t2m','sp','msl','t_850','u_1000','v_1000','z_1000','u_850','v_850',\n",
    "            'z_850','u_500','v_500','z_500','t_500','z_50','r_500','r_850','tcwv']\n",
    "\n",
    "filename = \"../../source_code/FCN/output/autoregressive_predictions_z500_vis.h5\"\n",
    "hf = h5py.File(filename, 'r')\n",
    "data = hf.get('predicted')[0]\n",
    "\n",
    "####### TODO ########\n",
    "j=19\n",
    "###################### \n",
    "    \n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    # Get the graph \n",
    "    plt.imshow(data[i][j],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # Save as image\n",
    "    store_loc = \"/../../source_code/extension/assets/FCN_output/\"+variable[j]+'/'\n",
    "    if not os.path.exists(os.getcwd()+store_loc):\n",
    "        os.makedirs(os.getcwd()+store_loc)\n",
    "    plt.savefig(os.getcwd()+store_loc+str(i)+'.jpg',bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n",
    "hf.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Modifying the extension to use the inputs for Total column water vapor\n",
    "\n",
    "\n",
    "Modify the extension here - [`extension.py`](../../source_code/extension/omniverse-project-navier-stokes/exts/omniverse.extension.navierstokes/omniverse/extension/navierstokes/extension.py)\n",
    "\n",
    "Since it autoloads everytime you save, you can simple save and head over to Omniverse window to visualise the results.\n",
    "\n",
    "```python\n",
    "import omni.ext\n",
    "import omni.ui as ui\n",
    "from pxr import Usd, UsdShade, Sdf\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# Any class derived from `omni.ext.IExt` in top level module (defined in `python.modules` of `extension.toml`) will be\n",
    "# instantiated when extension gets enabled and `on_startup(ext_id)` will be called. Later when extension gets disabled\n",
    "# on_shutdown() is called.\n",
    "class OmniverseExtensionNavierstokesExtension(omni.ext.IExt):\n",
    "    # ext_id is current extension id. It can be used with extension manager to query additional information, like where\n",
    "    # this extension is located on filesystem.\n",
    "    def on_startup(self, ext_id):\n",
    "        print(\"[omniverse.extension.navierstokes] omniverse extension navierstokes startup\")\n",
    "        \n",
    "        # Get shader input for opacity map\n",
    "        stage = omni.usd.get_context().get_stage()\n",
    "        shader = UsdShade.Shader.Get(stage,\"/World/Looks/Clouds/Shader\")\n",
    "        texture = shader.GetInput(\"opacity_texture\")\n",
    "        \n",
    "        # Get and store image paths \n",
    "        files=[]\n",
    "        for i in range(30):\n",
    "            ##################### TODO #####################\n",
    "            files.append(os.getcwd()+'/../extension/assets/FCN_output/u10/'+str(i)+'.jpg')\n",
    "            ################################################\n",
    "        \n",
    "        # Assign images every 5 timesteps\n",
    "        texture.GetAttr().Clear()\n",
    "        for i in range(30):\n",
    "            texture.Set(Sdf.AssetPath(files[i]),Usd.TimeCode(5*i))\n",
    "                        \n",
    "        # Trim Timeline\n",
    "        stage.SetStartTimeCode(0)\n",
    "        stage.SetEndTimeCode(150)\n",
    "        \n",
    "        \n",
    "    def on_shutdown(self):\n",
    "        print(\"[omniverse.extension.navierstokes] omniverse extension navierstokes shutdown\")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "##################### Solution #####################\n",
    "import omni.ext\n",
    "import omni.ui as ui\n",
    "from pxr import Usd, UsdShade, Sdf\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# Any class derived from `omni.ext.IExt` in top level module (defined in `python.modules` of `extension.toml`) will be\n",
    "# instantiated when extension gets enabled and `on_startup(ext_id)` will be called. Later when extension gets disabled\n",
    "# on_shutdown() is called.\n",
    "class OmniverseExtensionNavierstokesExtension(omni.ext.IExt):\n",
    "    # ext_id is current extension id. It can be used with extension manager to query additional information, like where\n",
    "    # this extension is located on filesystem.\n",
    "    def on_startup(self, ext_id):\n",
    "        print(\"[omniverse.extension.navierstokes] omniverse extension navierstokes startup\")\n",
    "        \n",
    "        # Get shader input for opacity map\n",
    "        stage = omni.usd.get_context().get_stage()\n",
    "        shader = UsdShade.Shader.Get(stage,\"/World/Looks/Clouds/Shader\")\n",
    "        texture = shader.GetInput(\"opacity_texture\")\n",
    "        \n",
    "        # Get and store image paths \n",
    "        files=[]\n",
    "        for i in range(32):\n",
    "            ##################### TODO #####################\n",
    "            files.append(os.getcwd()+'/../extension/assets/FCN_output/tcwv/'+str(i)+'.jpg')\n",
    "            ################################################\n",
    "        \n",
    "        # Assign images every 5 timesteps\n",
    "        texture.GetAttr().Clear()\n",
    "        for i in range(32):\n",
    "            texture.Set(Sdf.AssetPath(files[i]),Usd.TimeCode(5*i))\n",
    "                        \n",
    "        # Trim Timeline\n",
    "        stage.SetStartTimeCode(0)\n",
    "        stage.SetEndTimeCode(160)\n",
    "        \n",
    "        \n",
    "    def on_shutdown(self):\n",
    "        print(\"[omniverse.extension.navierstokes] omniverse extension navierstokes shutdown\")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "\n",
    "#### 1. Setting a blue tint\n",
    "\n",
    "Since we are visualising the Total column water vapor, we can set the opacity map to have a blue tint as a representation to the water vapor, this can be done by selecting our `Clouds` Material and scrolling down to `Albedo` section and setting the color tint to a slightly blue shade. \n",
    "\n",
    "<center><img src=\"images/ext11.png\" alt=\"Drawing\" style=\"width:350px\" /></center>\n",
    "\n",
    "#### 2. Using the Movie Capture Extension\n",
    "\n",
    "This extension allows us to render visually beautiful outputs as a video file, let us now enable this extension and create a render. \n",
    "\n",
    "Select `Window->Extensions` to open the extensions window and search for `Movie Capture` and enable the extension.\n",
    "\n",
    "<center><img src=\"images/ext12.png\" alt=\"Drawing\" style=\"width:800px\" /></center>\n",
    "\n",
    "\n",
    "Once the Movie Capture extension is enabled, you can notice the Movie Capture window is displayed, you can set the following parameters. \n",
    "- **FPS**: You can choose an FPS, a `30 FPS` setting will create a 5 second clip as we have used 150 frames.\n",
    "- **Render Preset**: We can set it to `RTX-Interactive` for a much visually appealing render. \n",
    "- **Path**: We can then set the path to where we want our output render to be saved, since all our files are in the `/workspace/python/source_code/extension/` folder, we can set it to save the file in this folder. \n",
    "- **Name**: We can set it to `tcwv` and give the `.mp4` extension. \n",
    "\n",
    "Once we change all the values, we can go ahead and `Capture Sequence`, it will take a few minutes to render and store the video file. \n",
    "\n",
    "<center><img src=\"images/ext13.png\" alt=\"Drawing\" style=\"width:350px\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final render would look close to the below video clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"images/tcwv.mp4\" controls loop autoplay  width=\"1200\"  height=\"600\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"images/tcwv.mp4\",width=1200, height=600,html_attributes='controls loop autoplay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on successfully developing the extensions with NVIDIA Omniverse! \n",
    "\n",
    "While the scope of the bootcamp is to introduce you to Omniverse and build an extension to visualise the results, we suggest you get creative and try implementing additional modifications, such as integrating a skybox and incorporating a dropdown menu to enable the selection of variables for display. \n",
    "\n",
    "Kindly go back to the first notebook to interrupt the Omniverse command once you have completed the bootcamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Don't forget to check out additional [Open Hackathons Resources](https://www.openhackathons.org/s/technical-resources) and join our [OpenACC and Hackathons Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
    "\n",
    "---\n",
    "\n",
    "# Licensing\n",
    "\n",
    "Copyright © 2023 OpenACC-Standard.org.  This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials may include references to hardware and software developed by other entities; all applicable licensing and copyrights apply.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
